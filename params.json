{"name":"Locality-constrained-linear-coding-for-scene-classification","tagline":"","body":"\r\n##Project Description\r\n\r\nIn this project, you will implement the LLC (Locality-constrained Linear Coding) method[2] for image classification and apply your method on a natural scene classification dataset.\r\n\r\n## Implementation\r\n\r\n1. Extract SIFT features from each image.\r\n2. Build dictionary use K-means from feature vectors.\r\n3. Encode each feature vector via dictionary using LLC.\r\n4. In Spatial Pyramid Matching part, the pooled features from each sub-region are concatenated and normalized as the final image feature representation. In this paper, we use max pooling combined with sum normalization.\r\n\r\n## DataSet \r\n\r\nThe dataset we used is composed of fifteen scene categories by Svetlana Lazebnik et.al[1].  Each category has 200 to 400 images, and average image size is 300 Ã— 250 pixels. The major sources\r\nof the pictures in the dataset include the COREL collection,\r\npersonal photographs, and Google image search. \r\n\r\n## Evaluation\r\n\r\nWhen evaluate our model, we use a typical training/test split: 100 images per class for training and the rest for testing. \r\n\r\nWe report the confusion matrix for the fifteen scenes categories as well as the mean accuracy.\r\n\r\nIn the mean accuracy measure, we calculate the accuracy of each class, and average the accuracy values of all classes. \r\n\r\n## Spatial Pyramid Matching with Hard Coding\r\n\r\nAfter building dictionary, for each feature vector, we assign it to its closed cluster in dictionary. In other words, each feature vector is assigned to only one cluster. Note that in this experiment, different levels of features are concatenated with different weights. For the features in level k, its weight will be 1/2^(L-k), where L is the number of levels.\r\n\r\n###Parameter Setting\r\n\r\n    params.maxImageSize = 1000;\r\n    params.gridSpacing = 8;\r\n    params.patchSize = 16;\r\n    params.dictionarySize = 200;\r\n    params.numTextonImages = 100;\r\n    params.pyramidLevels = 3;\r\n\r\n### Linear Kernel\r\n\r\nWe first built the model using linear kernel.  The features for each instance is hard-coded word. LibLinear[3] is used to train the model. The results we get is 0.7267.\r\n\r\nNormalized Confusion Matrix\r\n\r\nNote that the y-axis is the true label, the x-axis is the predicted label.\r\n\r\n![](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/nonLLC-3-5-200.jpg?raw=true)\r\n\r\nNon-Normalized Confusion Matrix\r\n\r\n![](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/nonLLC-3-5-200-Raw.jpg?raw=true)\r\n\r\n### Histogram Intersection Kernel\r\n\r\nWe also built the model using histogram intersection kernel. We first to calculate the kernel for each instance, then train the non-linear SVM model using our kernel. The results we get is 0.8664.\r\n\r\nNormalized Confusion Matrix\r\n\r\nNote that the y-axis is the true label, the x-axis is the predicted label.\r\n\r\n![](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/nonLLC_kernel-3-5-200.jpg?raw=true)\r\n\r\nNon-Normalized Confusion Matrix\r\n\r\n![](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/nonLLC_kernel-3-5-200-Raw.jpg?raw=true)\r\n\r\n\r\n### Summary\r\n\r\nBased on the results, we can see using the histogram intersection kernel does improve our classification model. But due the computation for kernel, the computation complexity is higher than the linear SVM.\r\n\r\n## Locality-constrained Linear Coding\r\n\r\nLLC utilizes the locality constraints to project each descriptor into its local-coordinate system, and the projected coordinates are integrated by max pooling to generate the final representation.\r\n\r\n### Parameter Setting\r\n\r\n\r\n    params.maxImageSize = 1000;\r\n    params.gridSpacing = 8;\r\n    params.patchSize = 16;\r\n    params.dictionarySize = 1024;\r\n    params.numTextonImages = 100;\r\n    params.pyramidLevels = 3;\r\n    params.K = 5;\r\n    liblinear.solver = 4;\r\n    liblinear.C = 32;\r\n    liblinear.B = 1;\r\n    \r\n### Result\r\n\r\nThe mean accuracy we got is 98.57%.\r\n\r\nNormalized Confusion Matrix\r\n\r\nNote that the y-axis is the true label, the x-axis is the predicted label.\r\n\r\n![Confusion Matrix](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/LLC-3-5-1024.jpg?raw=true)\r\n\r\nNon-Normalized Confusion Matrix\r\n\r\n![](https://github.com/wwu137/Locality-constrained-Linear-Coding-for-Scene-Classification/blob/master/result/LLC-3-5-1024-Raw.jpg?raw=true)\r\n\r\n### Different Parameter Settings\r\n\r\n#### Vary Solver\r\nFirst, we tried eight different solvers in liblinear.\r\n\r\n| Solver                                                        | Mean Accuracy |\r\n|---------------------------------------------------------------|----------|\r\n| L2-regularized logistic regression (primal)                   | 0.9590   |\r\n| L2-regularized L2-loss support vector classification (dual)   | 0.9786   |\r\n| L2-regularized L2-loss support vector classification (primal) | 0.9790   |\r\n| L2-regularized L1-loss support vector classification (dual)   | 0.9730   |\r\n| support vector classification by Crammer and Singer           | 0.9819   |\r\n| L1-regularized L2-loss support vector classification          | 0.9013   |\r\n| L1-regularized logistic regression                            | 0.7865   |\r\n| L2-regularized logistic regression (dual)                     | 0.9590   |\r\n\r\n#### Vary Cost\r\n\r\nWe use the default solver: L2-regularized L2-loss support vector classification but with different cost. The results are\r\n\r\n| C    | Mean Accuracy |\r\n|------|---------------|\r\n| 32   | 0.9837        |\r\n| 4    | 0.9826        |\r\n| 2    | 0.9813        |\r\n| 1    | 0.9786        |\r\n| 1/2  | 0.9760        |\r\n| 1/4  | 0.9710        |\r\n| 1/32 | 0.9543        |\r\n\r\nWe can see that with larger cost, the mean accuracy will increase.\r\n\r\n#### Bias\r\nWe use the default solver and set Cost to be 1, we test the model with and without bias.\r\n\r\n| Bisa         | Mean Accuracy |\r\n|--------------|---------------|\r\n| With Bias    | 0.9799        |\r\n| Without Bias | 0.9786        |\r\n\r\nWe can see that with bias, we can improve the performance a bit.\r\n\r\n#### Dictionary Size\r\n\r\n| Dictionary Size | Mean Accuracy |\r\n|-----------------|---------------|\r\n| 200             | 0.9892        |\r\n| 512             | 0.9859        |\r\n| 1024            | 0.9859        |\r\n\r\n\r\n## Reference\r\n\r\n1. Lazebnik, S., Schmid, C., & Ponce, J. (2006). *Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories*. In Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on (Vol. 2, pp. 2169-2178). IEEE.\r\n2. Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., & Gong, Y. (2010, June). *Locality-constrained linear coding for image classification*. In Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on (pp. 3360-3367). IEEE.\r\n3. Fan, R. E., Chang, K. W., Hsieh, C. J., Wang, X. R., & Lin, C. J. (2008). *LIBLINEAR: A library for large linear classification*. The Journal of Machine Learning Research, 9, 1871-1874.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}